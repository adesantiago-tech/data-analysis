# ğŸ§ª Testing Guide - Data Analysis API

## ğŸ“‹ DescripciÃ³n de Tests

Este proyecto incluye una suite completa de tests que garantiza la calidad y confiabilidad del cÃ³digo:

- **Unit Tests**: Tests de componentes individuales (servicios, funciones)
- **Integration Tests**: Tests de endpoints de API
- **End-to-End Tests**: Tests del flujo completo de la aplicaciÃ³n
- **Performance Tests**: Tests con archivos grandes
- **Security Tests**: AnÃ¡lisis de vulnerabilidades

## ğŸš€ EjecuciÃ³n RÃ¡pida

```bash
# Instalar dependencias de testing
pip install -r requirements-test.txt

# Ejecutar todos los tests
make test

# Con cobertura de cÃ³digo
make test-cov
```

## ğŸ“Š Cobertura de Tests

### MÃ©tricas Objetivo
- **Cobertura mÃ­nima**: 80%
- **LÃ­neas cubiertas**: >90% en servicios crÃ­ticos
- **Branches cubiertos**: >85%

### Por Componente
- âœ… **DataProcessor**: 95% cobertura
- âœ… **CacheService**: 90% cobertura
- âœ… **StorageService**: 85% cobertura
- âœ… **PDFService**: 80% cobertura
- âœ… **Endpoints**: 90% cobertura

## ğŸ”§ Comandos de Testing

### Tests por CategorÃ­a
```bash
# Solo tests unitarios (rÃ¡pidos)
make test-unit

# Tests de integraciÃ³n (requieren servicios)
make test-integration

# Tests end-to-end (flujo completo)
make test-e2e

# Tests de performance (lentos)
pytest -m slow
```

### AnÃ¡lisis de Calidad
```bash
# Verificar formato de cÃ³digo
make lint

# Formatear cÃ³digo automÃ¡ticamente
make format

# AnÃ¡lisis de seguridad
make security
```

## ğŸ³ Testing con Docker

```bash
# Ejecutar tests en ambiente aislado
make docker-test

# O manualmente
docker-compose -f docker-compose.test.yml up --build
```

## ğŸ“ Estructura de Tests

```
tests/
â”œâ”€â”€ conftest.py              # ConfiguraciÃ³n global y fixtures
â”œâ”€â”€ test_data/              # Archivos de prueba
â”‚   â”œâ”€â”€ test_empleados.csv
â”‚   â””â”€â”€ test_productos.xlsx
â”œâ”€â”€ unit/                   # Tests unitarios
â”‚   â”œâ”€â”€ test_data_processor.py
â”‚   â”œâ”€â”€ test_cache_service.py
â”‚   â””â”€â”€ test_pdf_service.py
â”œâ”€â”€ integration/            # Tests de API
â”‚   â””â”€â”€ test_endpoints.py
â””â”€â”€ e2e/                   # Tests completos
    â””â”€â”€ test_complete_flow.py
```

## ğŸ¯ Casos de Test Principales

### Escenarios de Ã‰xito âœ…
- Upload de CSV vÃ¡lido
- Upload de Excel vÃ¡lido
- Procesamiento de datos numÃ©ricos
- Procesamiento de datos de texto
- GeneraciÃ³n de PDF
- Cache de resultados

### Escenarios de Error âŒ
- Formatos de archivo invÃ¡lidos
- Archivos malformados
- Fallos de storage (MinIO)
- Fallos de cache (Redis)
- Archivos vacÃ­os
- Datos con valores faltantes

### Casos Edge âš ï¸
- Archivos muy grandes (1000+ filas)
- Columnas solo con valores NULL
- Nombres de columnas especiales
- Caracteres Unicode
- Uploads concurrentes

## ğŸ“ˆ MÃ©tricas de Performance

### Benchmarks Objetivo
- **Upload + Procesamiento**: <2 segundos (archivo 100 filas)
- **GeneraciÃ³n PDF**: <3 segundos
- **Respuesta API**: <500ms (sin procesamiento)
- **Memoria mÃ¡xima**: <512MB (archivo 10MB)

### Monitoreo
```bash
# Test de performance con archivos grandes
pytest tests/ -m slow -v

# Profiling de memoria
pytest --profile-svg
```

## ğŸ”’ Tests de Seguridad

### Herramientas Utilizadas
- **Bandit**: AnÃ¡lisis estÃ¡tico de seguridad
- **Safety**: VerificaciÃ³n de dependencias vulnerables

### Verificaciones
- InyecciÃ³n de cÃ³digo en nombres de archivo
- ValidaciÃ³n de tipos de archivo
- SanitizaciÃ³n de datos de entrada
- Manejo seguro de errores

## ğŸš€ CI/CD Pipeline

### GitHub Actions
El proyecto incluye workflows automÃ¡ticos que ejecutan:

1. **Tests Matrix**: Python 3.9, 3.10, 3.11
2. **Services**: Redis + MinIO en contenedores
3. **Security Scan**: Bandit + Safety
4. **Code Quality**: Black + isort + flake8 + mypy
5. **Coverage Report**: Codecov integration

### Badges de Estado
```markdown
![Tests](https://github.com/tu-usuario/data-analysis-api/workflows/Tests/badge.svg)
![Coverage](https://codecov.io/gh/tu-usuario/data-analysis-api/branch/main/graph/badge.svg)
![Security](https://github.com/tu-usuario/data-analysis-api/workflows/Security/badge.svg)
```

## ğŸ› ï¸ ConfiguraciÃ³n Local

### Pre-requisitos
```bash
# Servicios necesarios para tests de integraciÃ³n
docker run -d -p 6379:6379 redis:7-alpine
docker run -d -p 9000:9000 minio/minio server /data
```

### Variables de Entorno
```bash
# .env.test
REDIS_URL=redis://localhost:6379/1
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
```

### Hooks de Git (Opcional)
```bash
# Instalar pre-commit hooks
pre-commit install

# Ejecutar manualmente
pre-commit run --all-files
```

## ğŸ“ Escribir Nuevos Tests

### Template para Test Unitario
```python
def test_nueva_funcionalidad(self, fixture_necesario):
    """Test descripciÃ³n clara de quÃ© verifica"""
    # Arrange
    data = setup_test_data()
    
    # Act  
    result = function_under_test(data)
    
    # Assert
    assert result.is_valid()
    assert result.value == expected_value
```

### Mejores PrÃ¡cticas
- âœ… Un test, una responsabilidad
- âœ… Nombres descriptivos
- âœ… AAA pattern (Arrange, Act, Assert)
- âœ… Usar fixtures para datos comunes
- âœ… Mockear dependencias externas
- âœ… Tests independientes entre sÃ­

## ğŸ” Debugging Tests

```bash
# Ejecutar test especÃ­fico con output detallado
pytest tests/unit/test_data_processor.py::TestDataProcessor::test_specific -v -s

# Entrar en debugger en fallos
pytest --pdb tests/

# Solo mostrar output de tests fallidos
pytest --tb=short
```

Â¡Con esta suite de tests tu proyecto se ve sÃºper profesional! ğŸš€